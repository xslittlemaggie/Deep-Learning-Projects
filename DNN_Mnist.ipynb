{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN_Mnist_LH.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xslittlemaggie/Deep-Learning-Projects/blob/master/DNN_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IdKbNDks5sy",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Import librarious"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbi4948Ys3bY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9604MxXtDt4",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmTJ3YZWqO2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  number = 10000\n",
        "  x_train = x_train[0:number]\n",
        "  y_train = y_train[0:number]\n",
        "  x_train = x_train.reshape(number, 28 * 28)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  # convert class vectors to binary class matrices\n",
        "  y_train = np_utils.to_categorical(y_train, 10)\n",
        "  y_test = np_utils.to_categorical(y_test, 10)\n",
        "  \n",
        "  x_train = x_train\n",
        "  x_test = x_test\n",
        "  \n",
        "  x_train = x_train/255   # normalize the input, if not normalized, the accuracy decreases significantly\n",
        "  x_test = x_test/255\n",
        "  #x_test = np.random.normal(x_test)  # add random noise to testing data, this would decrease the test accuracy\n",
        "  return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBYJB-FvqVvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUSQTE4DtJXw",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Get familiar with the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjjaYXfzqrx7",
        "colab_type": "code",
        "outputId": "47672875-b984-4522-cab9-7c0db597334a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (10000, 784)\n",
            "y_train shape: (10000, 10)\n",
            "x_test shape: (10000, 784)\n",
            "y_test shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lWNp13nqyeI",
        "colab_type": "code",
        "outputId": "db174f70-edb6-489d-81dd-e78ef48cc9ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(y_train[0]) # the first value is 5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e40ewWHUuN57",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Create the DNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHp3YTBgzV1x",
        "colab_type": "text"
      },
      "source": [
        "Models:\n",
        "      **1). Dense -> fully connected NN**\n",
        "      **2). MaxPooling**\n",
        "      **3). Conv2D -> CNN**\n",
        "      **4). Flatten**\n",
        "\n",
        "\n",
        "1. Activation functions: \n",
        "      **1). relu** (more efficient)\n",
        "      **2). sigmoid**\n",
        "      **3). tanh**\n",
        "      **4). softmax** (usually the last layer)\n",
        "      \n",
        "2. Loss functions: \n",
        "      **1). mse** (not good for classification)\n",
        "      **2). categorical_crossentropy**\n",
        "      \n",
        "3. Optimizers: \n",
        "      **1). SGD(lr = 0.01)**\n",
        "      **2). Adam**\n",
        "      \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm0gF8PWsvy9",
        "colab_type": "code",
        "outputId": "6da7325b-f339-4b8a-9a11-cb6979d71b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(input_dim = 28 * 28, units = 512, activation = 'relu'))  # only need to add the input_dim at the first layer)\n",
        "#model.add(Dropout(0.2))  # if there is overfitting, use dropout, add dropout at every hidden\n",
        "\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "#for i in range(10):  # add more layers, not work\n",
        "#  model.add(Dense(units = 512, activation = 'relu'))   \n",
        "\n",
        "\n",
        "model.add(Dense(units = 10, activation = 'softmax')) # the units (neurons) of the last layer need to be the # of classes\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size = 100, epochs = 30)\n",
        "\n",
        "result = model.evaluate(x_train, y_train, batch_size = 10000)\n",
        "print(\"Train Acc:\", result[1])\n",
        "print()\n",
        "\n",
        "result = model.evaluate(x_test, y_test, batch_size = 10000)\n",
        "print(\"Test Acc:\", result[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10000/10000 [==============================] - 1s 102us/step - loss: 0.4608 - acc: 0.8656\n",
            "Epoch 2/30\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.1524 - acc: 0.9561\n",
            "Epoch 3/30\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0958 - acc: 0.9700\n",
            "Epoch 4/30\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0536 - acc: 0.9843\n",
            "Epoch 5/30\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 0.0319 - acc: 0.9903\n",
            "Epoch 6/30\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0407 - acc: 0.9868\n",
            "Epoch 7/30\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 0.0213 - acc: 0.9936\n",
            "Epoch 8/30\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0182 - acc: 0.9938\n",
            "Epoch 9/30\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0228 - acc: 0.9931\n",
            "Epoch 10/30\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0201 - acc: 0.9934\n",
            "Epoch 11/30\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 0.0099 - acc: 0.9967\n",
            "Epoch 12/30\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0168 - acc: 0.9957\n",
            "Epoch 13/30\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0122 - acc: 0.9956\n",
            "Epoch 14/30\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0242 - acc: 0.9935\n",
            "Epoch 15/30\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0139 - acc: 0.9956\n",
            "Epoch 16/30\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0164 - acc: 0.9955\n",
            "Epoch 17/30\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 0.0120 - acc: 0.9960\n",
            "Epoch 18/30\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0267 - acc: 0.9927\n",
            "Epoch 19/30\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0140 - acc: 0.9950\n",
            "Epoch 20/30\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0108 - acc: 0.9969\n",
            "Epoch 21/30\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0041 - acc: 0.9988\n",
            "Epoch 22/30\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 3.4836e-04 - acc: 1.0000\n",
            "Epoch 23/30\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 8.1696e-05 - acc: 1.0000\n",
            "Epoch 24/30\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 5.8720e-05 - acc: 1.0000\n",
            "Epoch 25/30\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 4.6870e-05 - acc: 1.0000\n",
            "Epoch 26/30\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 3.8989e-05 - acc: 1.0000\n",
            "Epoch 27/30\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 3.3164e-05 - acc: 1.0000\n",
            "Epoch 28/30\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 2.8590e-05 - acc: 1.0000\n",
            "Epoch 29/30\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 2.4991e-05 - acc: 1.0000\n",
            "Epoch 30/30\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 2.1839e-05 - acc: 1.0000\n",
            "10000/10000 [==============================] - 0s 9us/step\n",
            "Train Acc: 1.0\n",
            "\n",
            "10000/10000 [==============================] - 0s 4us/step\n",
            "Test Acc: 0.9682000279426575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWkq9xZNOdM-",
        "colab_type": "text"
      },
      "source": [
        "Result analysis:\n",
        "\n",
        "**Train** acc: 1\n",
        "\n",
        "**Test** acc: 0.97\n",
        "\n",
        "It looks good!\n",
        "\n"
      ]
    }
  ]
}